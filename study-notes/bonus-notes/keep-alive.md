# Keep-Alive, 소켓 풀, 그리고 HTTP/2의 변화

## 1. Keep-Alive: TCP 연결의 재사용

Keep-Alive는 HTTP/1.1부터 도입된 기능으로, 한 번 맺은 TCP 연결을 여러 HTTP 요청과 응답에 걸쳐 재사용하도록 하여 연결 생성 및 해제 오버헤드를 줄입니다.

- **Keep-Alive 없음 (HTTP/1.0):** 매 요청마다 `연결(3-way handshake) → 데이터 전송 → 연결 종료(4-way handshake)` 과정 반복. 많은 연결 오버헤드가 발생했습니다.

  ```
  요청 1: connect → send → recv → close
  요청 2: connect → send → recv → close
  요청 3: connect → send → recv → close
  ```

- **Keep-Alive 있음 (HTTP/1.1):** 한 번의 `connect`로 연결을 맺은 후, 여러 요청을 보내고 응답을 받은 뒤 마지막에 `close`하여 연결 오버헤드를 크게 줄입니다.
  ```
  connect → send → recv → send → recv → send → recv → close
  ```

## 2. 소켓 풀: 재사용 가능한 TCP 연결 관리

소켓 풀은 Keep-Alive를 통해 재사용 가능한 TCP 연결들을 관리하는 저장소입니다. 이는 클라이언트(브라우저)나 서버 애플리케이션에서 네트워크 자원을 효율적으로 사용하기 위해 구현됩니다.

- **기본 작동 방식:**

  1.  요청할 호스트에 대해 풀에 유휴(Idle) 소켓(TCP 연결)이 있는지 확인합니다.
  2.  있으면 해당 소켓을 재사용합니다.
  3.  없으면 새로운 소켓을 생성(3-way handshake)하여 연결하고 풀에 추가합니다.
  4.  요청 처리 후, 소켓은 즉시 닫히지 않고 풀에 유지되어 다음 요청에 재사용될 수 있도록 대기합니다.
  5.  일정 시간 이상 사용되지 않으면(유휴 타임아웃) 소켓은 자동으로 닫힙니다(4-way handshake).

- **의사코드 (개념):**

  ```python
  socket_pool = {} # 호스트별 또는 그룹별로 관리되는 연결들

  def get_connection(host):
      # 풀에서 유효한 연결을 찾거나 새로 생성하여 반환
      # (실제 구현은 동시성, 타임아웃, 에러 처리 등 복잡)
      pass

  # 요청 흐름 예시:
  conn = get_connection(url.host)
  conn.send(request)
  response = conn.recv()
  # conn은 닫지 않고 풀에 반환 (재사용 대기)
  ```

## 3. HTTP/1.x의 소켓 연결 제한 및 문제점

### 3.1. HOL (Head Of Line) Blocking이란?

**HOL Blocking**은 앞선 요청이 처리될 때까지 뒤따르는 요청들이 대기해야 하는 현상입니다.

- **HTTP/1.1의 HOL Blocking**: 하나의 TCP 연결에서 요청-응답이 순서대로 처리되어야 하므로, 첫 번째 요청이 느리면 두 번째, 세 번째 요청이 모두 대기하게 됩니다.

  ```
  요청1 (느림, 5초) → 요청2 (빠름, 0.1초) → 요청3 (빠름, 0.1초)
  실제 소요 시간: 5.2초 (요청2, 3은 요청1이 끝날 때까지 대기)
  ```

- **해결 방법**: HTTP/1.1에서는 여러 개의 TCP 연결을 동시에 열어 병렬 처리함으로써 이 문제를 우회했습니다.

### 3.2. 브라우저의 연결 제한

HTTP/1.1 환경에서 클라이언트(특히 브라우저)는 HOL(Head Of Line) Blocking 문제를 우회하고 병렬성을 확보하기 위해 하나의 호스트에 대해 여러 개의 TCP 연결을 동시에 유지했습니다.

- **브라우저의 호스트당 연결 제한 (최대 6개):**
  Chrome을 포함한 대부분의 브라우저는 **한 호스트(도메인)당 동시 TCP 연결 수를 기본적으로 6개**로 제한했습니다. 이는 무분별한 연결로 서버에 과부하를 주는 것을 방지하기 위함이었습니다.

  ```cpp
  // Chromium 설정 예시 (개념 설명용 의사코드)
  const int kDefaultMaxSocketsPerGroup = 6;  // 호스트당 최대 6개 연결
  const int kIdleSocketTimeout = 300;        // 유휴 연결 5분 후 종료
  ```

- **워터폴(Waterfall) 현상:**
  이 제한으로 인해, 만약 한 도메인에서 6개 이상의 리소스가 동시에 요청되면, 7번째 요청부터는 앞선 6개 중 하나가 완료되어 소켓이 반환될 때까지 **대기하는 현상(워터폴)**이 발생했습니다. 이는 Chrome 개발자 도구의 네트워크 탭에서 폭포수 형태로 지연이 발생하는 것으로 관찰됩니다.

## 4. HTTP/1.x 시대의 최적화 기법

### 4.1. Domain Sharding (도메인 샤딩)

HTTP/1.1의 "호스트당 6개 소켓 제한"을 우회하여 동시 다운로드 수를 늘리기 위한 클라이언트 측 기법입니다.

- **문제점:** 단일 도메인에서 7번째 리소스부터는 위에서 설명한 워터폴 현상으로 대기하게 됩니다.

  ```html
  <!-- cdn.example.com 도메인에 대해 6개 연결만 가능 -->
  <img src="http://cdn.example.com/1.jpg" />
  <!-- 1번 연결 -->
  ...
  <img src="http://cdn.example.com/6.jpg" />
  <!-- 6번 연결 -->
  <img src="http://cdn.example.com/7.jpg" />
  <!-- 6개 중 하나가 끝나야 대기 해제 -->
  ```

- **해결책:** 여러 개의 서브 도메인(예: `cdn1.example.com`, `cdn2.example.com`)을 사용하여 리소스들을 분산 배치함으로써, 각 서브 도메인별로 6개씩의 TCP 연결을 추가로 확보하여 동시 다운로드 수를 늘립니다.
  ```html
  <!-- cdn1, cdn2, cdn3, cdn4 각각 6개씩 연결 → 총 24개 동시 연결 가능 -->
  <img src="http://cdn1.example.com/1.jpg" />
  <img src="http://cdn2.example.com/2.jpg" />
  <img src="http://cdn3.example.com/3.jpg" />
  <img src="http://cdn4.example.com/4.jpg" />
  ```

### 4.2. BFF (Backend For Frontend)와 서버 간 통신

BFF는 클라이언트(브라우저) 요청을 받아 여러 백엔드 서비스에 다시 요청하고 응답을 조합하여 클라이언트에 제공하는 중간 계층입니다. 이는 HTTP 버전과 무관하게 현재도 널리 사용되는 아키텍처 패턴이지만, HTTP/1.x 시대에는 특히 브라우저의 연결 제한 문제를 해결하는 데 도움이 되었습니다.

- **서버 간 통신의 유연성:** 서버는 브라우저보다 훨씬 많은 시스템 자원과 네트워크 제어 권한을 가지므로, 백엔드 서비스 간의 통신(예: BFF가 여러 마이크로 서비스에 요청)에서는 브라우저와 같은 **엄격한 `호스트당 6개` 제한이 적용되지 않았습니다.** 대신 **더 유연한 소켓 풀 전략을 사용**할 수 있었습니다. 예를 들어, 자체적으로 수십, 수백 개의 Keep-Alive 연결을 풀링하여 사용함으로써 성능을 최적화했습니다.
- **적절한 최적화 예시:** HTTP/1.x에서도 서버 내부에서는 Domain Sharding과 같은 우회 기법 없이, 연결 풀링을 통해 효율적인 통신이 가능했습니다. 이는 "요청 수 제한"이 아닌, "브라우저의 동시 연결 수 제한"이 HTTP/1.x의 핵심 제약이었음을 보여줍니다.

## 5. HTTP/2 시대의 변화

HTTP/2는 `멀티플렉싱` 기능을 통해 단일 TCP 연결 위에서 여러 요청과 응답을 동시에, 비동기적으로 처리합니다.

- **단일 연결 원칙:** 기본적으로 **호스트당 하나의 TCP 연결**을 사용합니다. 일부 브라우저는 성능 최적화를 위해 2-3개의 연결을 사용하기도 하지만, HTTP/1.x처럼 6개씩 연결할 필요는 없습니다.

- **HOL Blocking의 부분적 해결:**

  - ✅ **애플리케이션 레벨 HOL Blocking 해결**: HTTP/1.1의 요청-응답 순서 문제가 해결되었습니다. 하나의 느린 응답이 다른 요청을 막지 않습니다.
  - ⚠️ **TCP 레벨 HOL Blocking 여전히 존재**: TCP 패킷 손실이 발생하면 해당 연결의 모든 스트림이 대기하게 됩니다. 이 문제는 HTTP/3(QUIC)에서 UDP 기반 프로토콜을 사용하여 완전히 해결됩니다.

- **Domain Sharding 불필요:** HTTP/1.x의 소켓 제한이 사라지므로 Domain Sharding은 더 이상 필요 없으며, 오히려 여러 도메인에 대한 추가적인 TLS 핸드셰이크 등으로 인해 성능 저하를 야기할 수 있어 **권장되지 않습니다.**

## 핵심 정리

- **Keep-Alive:** HTTP/1.1에서 TCP 연결을 재사용하여 오버헤드 감소.
- **소켓 풀:** Keep-Alive 연결을 관리하는 저장소.
- **HTTP/1.x 브라우저 제한:** 한 호스트당 최대 6개 TCP 연결 제한으로 **워터폴 현상** 발생.
- **Domain Sharding:** HTTP/1.1의 6개 제한을 우회하기 위한 **클라이언트 측 최적화.**
- **HTTP/2:** `멀티플렉싱`을 통해 단일 TCP 연결로 처리. 애플리케이션 레벨 HOL Blocking 해결, TCP 레벨 HOL Blocking은 여전히 존재 (HTTP/3에서 완전 해결). Domain Sharding은 불필요해짐.
